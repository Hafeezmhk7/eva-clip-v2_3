#!/bin/bash
#SBATCH --job-name=clip_repro_training
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=15:00:00
#SBATCH --mem=64G
#SBATCH --output=./slurm_out/clip_repro_%j.out
#SBATCH --error=./slurm_out/clip_repro_%j.err

echo "üöÄ CLIP Reproduction Training with BLIP3-o DiT"
echo "==============================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPUs: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | tr '\n' ', ')"
echo "==============================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Configuration
EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="./checkpoints/clip_repro_$(date +%Y%m%d_%H%M%S)"
TRAINING_MODE="patch_only"
MODEL_SIZE="base"

# Training hyperparameters
NUM_EPOCHS=10
BATCH_SIZE=16
LEARNING_RATE=5e-4
WEIGHT_DECAY=0.01
WARMUP_STEPS=100
MAX_GRAD_NORM=1.0

# =============================================================================
# CONFIGURABLE PARAMETERS - Edit values below
# =============================================================================
EVAL_EVERY_N_STEPS=326
EVAL_NUM_SAMPLES=10            # Change this number
EVAL_INFERENCE_STEPS=50
OVERFIT_TEST_SIZE=0            # 0=disabled, >0=enabled
DEBUG_MODE=false                # true=enabled, false=disabled
USE_WANDB=true                  # true=enabled, false=disabled
MAX_SHARDS=2
# =============================================================================

# Create output directory
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo "‚öôÔ∏è Configuration:"
echo "  Eval samples: $EVAL_NUM_SAMPLES"
echo "  Overfit test: $OVERFIT_TEST_SIZE"
echo "  Debug mode: $DEBUG_MODE"
echo "  WandB logging: $USE_WANDB"

# Verify embeddings exist
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "‚ùå Embeddings directory not found: $EMBEDDINGS_DIR"
    exit 1
fi

echo "üöÄ Starting training..."

# Launch training - Python handles all parameter logic
python train_dit.py \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --model_size "$MODEL_SIZE" \
    --training_mode "$TRAINING_MODE" \
    --learning_rate $LEARNING_RATE \
    --batch_size $BATCH_SIZE \
    --num_epochs $NUM_EPOCHS \
    --warmup_steps $WARMUP_STEPS \
    --weight_decay $WEIGHT_DECAY \
    --max_grad_norm $MAX_GRAD_NORM \
    --eval_every_n_steps $EVAL_EVERY_N_STEPS \
    --eval_num_samples $EVAL_NUM_SAMPLES \
    --overfit_test_size $OVERFIT_TEST_SIZE \
    --max_shards $MAX_SHARDS \
    --debug_mode $DEBUG_MODE \
    --use_wandb $USE_WANDB \
    --fp16

TRAINING_EXIT_CODE=$?

echo "========================================"
echo "üìä Training completed with exit code: $TRAINING_EXIT_CODE"
echo "========================================"

if [ $TRAINING_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Training successful"
    echo "üìÅ Results saved to: $OUTPUT_DIR"
else
    echo "‚ùå Training failed"
fi

exit $TRAINING_EXIT_CODE