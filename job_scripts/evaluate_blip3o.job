#!/bin/bash
#SBATCH --job-name=blip3o_coco_eval_std
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=2:00:00
#SBATCH --mem=32G
#SBATCH --output=./slurm_out/blip3o_coco_eval_std_%j.out
#SBATCH --error=./slurm_out/blip3o_coco_eval_std_%j.err

# =============================================================================
# BLIP3-o MS-COCO Evaluation with Standard Temp Directory Structure
# UPDATED: Uses standard temp directory and auto-detection of embeddings
# Memory-efficient evaluation using pre-extracted CLIP and EVA embeddings
# =============================================================================

echo "üî¨ BLIP3-o MS-COCO Evaluation with Standard Temp Directory"
echo "=================================================================="
echo "üî• UPDATED: Standard temp directory integration"
echo "üìÅ Auto-detection of COCO embeddings"
echo "üîó Consistent with training embeddings structure"
echo "=================================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "=================================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Standard temp directory paths
STANDARD_EMBEDDINGS_BASE="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings"
STANDARD_COCO_EMBEDDINGS_DIR="${STANDARD_EMBEDDINGS_BASE}/coco_embeddings"
STANDARD_TRAINING_EMBEDDINGS_DIR="${STANDARD_EMBEDDINGS_BASE}/patch_only_256_tokens"

# Configuration - can be overridden by command line arguments
MODEL_PATH="/home/azadaianchuk1/eva-clip-v6_2/checkpoints/blip3o_clean_20250803_015324"
OUTPUT_DIR="./coco_eval_std_$(date +%Y%m%d_%H%M%S)"

# Evaluation parameters
MAX_SAMPLES=1000  # Set to None or remove for all samples
BATCH_SIZE=8
NUM_INFERENCE_STEPS=50
USE_HEUN=true

# Parse command line arguments
if [ -n "$1" ]; then
    MODEL_PATH="$1"
    echo "üìÇ Using provided model path: $MODEL_PATH"
else
    echo "üìÇ Using default model path: $MODEL_PATH"
    # Auto-detect most recent model if default doesn't exist
    if [ ! -d "$MODEL_PATH" ]; then
        echo "üîç Auto-detecting most recent model..."
        MODEL_PATH=$(find ./checkpoints -name "*blip3o*" -type d | sort | tail -1)
        if [ -z "$MODEL_PATH" ]; then
            echo "‚ùå No model found! Please provide model path as first argument."
            echo "Usage: sbatch job_scripts/evaluate_blip3o_updated.job <model_path>"
            exit 1
        fi
        echo "üìÇ Found model: $MODEL_PATH"
    fi
fi

# Max samples can be provided as second argument
if [ -n "$2" ]; then
    MAX_SAMPLES="$2"
    echo "üìä Using provided max samples: $MAX_SAMPLES"
fi

# Batch size can be provided as third argument
if [ -n "$3" ]; then
    BATCH_SIZE="$3"
    echo "‚öôÔ∏è Using provided batch size: $BATCH_SIZE"
fi

# Create output directory
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "‚öôÔ∏è Standard Temp Directory MS-COCO Evaluation Configuration:"
echo "=========================================="
echo "Model: $MODEL_PATH"
echo "Standard Embeddings Base: $STANDARD_EMBEDDINGS_BASE"
echo "COCO Embeddings Dir: $STANDARD_COCO_EMBEDDINGS_DIR"
echo "Training Embeddings Dir: $STANDARD_TRAINING_EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo "Max Samples: ${MAX_SAMPLES:-All}"
echo "Batch Size: $BATCH_SIZE"
echo "Inference Steps: $NUM_INFERENCE_STEPS"
echo "Use Heun Solver: $USE_HEUN"
echo ""
echo "üöÄ Standard Temp Directory Strategy:"
echo "   ‚Ä¢ Auto-detection of COCO embeddings"
echo "   ‚Ä¢ Consistent directory structure with training"
echo "   ‚Ä¢ No need to specify embeddings file explicitly"
echo "   ‚Ä¢ Training statistics automatically loaded"
echo "   ‚Ä¢ Memory-efficient evaluation"
echo ""

# Verify model exists
if [ ! -d "$MODEL_PATH" ]; then
    echo "‚ùå Model directory not found: $MODEL_PATH"
    echo "Available models:"
    ls -la ./checkpoints/ 2>/dev/null || echo "No checkpoints found"
    exit 1
fi

# Check for required model files
MODEL_CONFIG="$MODEL_PATH/config.json"
MODEL_WEIGHTS_SAFETENSORS="$MODEL_PATH/model.safetensors"
MODEL_WEIGHTS_BIN="$MODEL_PATH/pytorch_model.bin"
CHECKPOINT_FILES="$MODEL_PATH/checkpoint_step_*.pt"

# Check what format the model is in
if [ -f "$MODEL_CONFIG" ] && ([ -f "$MODEL_WEIGHTS_SAFETENSORS" ] || [ -f "$MODEL_WEIGHTS_BIN" ]); then
    echo "‚úÖ HuggingFace format model detected"
elif ls $CHECKPOINT_FILES 1> /dev/null 2>&1; then
    echo "‚úÖ Checkpoint format model detected"
    LATEST_CHECKPOINT=$(ls -t $CHECKPOINT_FILES | head -1)
    echo "   Latest checkpoint: $LATEST_CHECKPOINT"
else
    echo "‚ùå No valid model files found in: $MODEL_PATH"
    echo "Expected:"
    echo "  - HuggingFace format: config.json + (model.safetensors OR pytorch_model.bin)"
    echo "  - Checkpoint format: checkpoint_step_*.pt"
    echo "Model directory contents:"
    ls -la "$MODEL_PATH"
    exit 1
fi

echo "‚úÖ Model verified: $MODEL_PATH"

# Verify standard temp directory structure
echo ""
echo "üîç Verifying Standard Temp Directory Structure..."
echo "================================================"

# Check base directory
if [ ! -d "$STANDARD_EMBEDDINGS_BASE" ]; then
    echo "‚ùå Standard embeddings base directory not found: $STANDARD_EMBEDDINGS_BASE"
    echo "Expected directory structure not available"
    exit 1
fi

echo "‚úÖ Standard embeddings base: $STANDARD_EMBEDDINGS_BASE"

# Check COCO embeddings directory
if [ ! -d "$STANDARD_COCO_EMBEDDINGS_DIR" ]; then
    echo "‚ùå COCO embeddings directory not found: $STANDARD_COCO_EMBEDDINGS_DIR"
    echo ""
    echo "üí° To extract COCO embeddings to standard location:"
    echo "   sbatch job_scripts/extract_coco_updated.job"
    exit 1
fi

echo "‚úÖ COCO embeddings directory: $STANDARD_COCO_EMBEDDINGS_DIR"

# Check for consolidated COCO embeddings file
COCO_CONSOLIDATED_FILE="$STANDARD_COCO_EMBEDDINGS_DIR/coco_embeddings_consolidated.pkl"
if [ ! -f "$COCO_CONSOLIDATED_FILE" ]; then
    echo "‚ùå COCO consolidated embeddings file not found: $COCO_CONSOLIDATED_FILE"
    echo ""
    echo "Available files in COCO embeddings directory:"
    ls -la "$STANDARD_COCO_EMBEDDINGS_DIR"
    echo ""
    echo "üí° If you see batch files, try consolidating them:"
    echo "   python extract_coco_embeddings_updated.py --consolidate_only"
    exit 1
fi

# Check COCO embeddings file size and details
EMBEDDINGS_SIZE=$(stat --format="%s" "$COCO_CONSOLIDATED_FILE" 2>/dev/null || echo "0")
EMBEDDINGS_SIZE_GB=$(echo "scale=2; $EMBEDDINGS_SIZE / 1024 / 1024 / 1024" | bc -l 2>/dev/null || echo "?.??")

echo "‚úÖ COCO consolidated embeddings file verified:"
echo "   File: $COCO_CONSOLIDATED_FILE"
echo "   Size: ${EMBEDDINGS_SIZE_GB} GB"

# Check manifest file
MANIFEST_FILE="$STANDARD_COCO_EMBEDDINGS_DIR/coco_embeddings_manifest.json"
if [ -f "$MANIFEST_FILE" ]; then
    echo "‚úÖ Manifest file found: $MANIFEST_FILE"
    
    # Extract info from manifest
    python -c "
import json
import sys
try:
    with open('$MANIFEST_FILE', 'r') as f:
        manifest = json.load(f)
    
    print(f'üìä COCO Embeddings Details:')
    print(f'   Total samples: {manifest.get(\"total_samples\", \"unknown\"):,}')
    print(f'   CLIP shape: {manifest.get(\"clip_shape\", \"unknown\")}')
    print(f'   EVA shape: {manifest.get(\"eva_shape\", \"unknown\")}')
    print(f'   Include CLS: {manifest.get(\"include_cls\", \"unknown\")}')
    print(f'   Tokens per sample: {manifest.get(\"tokens\", \"unknown\")}')
    print(f'   Created: {manifest.get(\"created\", \"unknown\")}')
    print(f'   Storage Location: {manifest.get(\"storage_location\", \"unknown\")}')
    
    # Verify it's in standard temp directory
    if manifest.get('storage_location') == 'standard_temp_dir':
        print(f'‚úÖ Confirmed: Stored in standard temp directory')
    
except Exception as e:
    print(f'Could not parse manifest: {e}')
    sys.exit(1)
"
else
    echo "‚ö†Ô∏è No manifest file found - will inspect embeddings during evaluation"
fi

# Check training embeddings directory for normalization
echo ""
echo "üîç Verifying training embeddings for normalization..."
if [ ! -d "$STANDARD_TRAINING_EMBEDDINGS_DIR" ]; then
    echo "‚ùå Training embeddings directory not found: $STANDARD_TRAINING_EMBEDDINGS_DIR"
    echo ""
    echo "‚ö†Ô∏è IMPORTANT: Training embeddings are needed for accurate normalization!"
    echo ""
    echo "Expected structure:"
    echo "  $STANDARD_TRAINING_EMBEDDINGS_DIR/"
    echo "  ‚îú‚îÄ‚îÄ embeddings_shard_00000_patch_only.pkl"
    echo "  ‚îú‚îÄ‚îÄ embeddings_shard_00001_patch_only.pkl"
    echo "  ‚îî‚îÄ‚îÄ ..."
    echo ""
    echo "‚ö†Ô∏è Proceeding with fallback - results may not be fully accurate"
    TRAINING_EMBEDDINGS_STATUS="‚ùå NOT FOUND (using fallback)"
else
    # Check for .pkl files
    PKL_COUNT=$(find "$STANDARD_TRAINING_EMBEDDINGS_DIR" -name "*.pkl" | wc -l)
    if [ $PKL_COUNT -eq 0 ]; then
        echo "‚ùå No .pkl files found in training embeddings directory"
        echo "Directory contents:"
        ls -la "$STANDARD_TRAINING_EMBEDDINGS_DIR"
        TRAINING_EMBEDDINGS_STATUS="‚ùå NO FILES (using fallback)"
    else
        echo "‚úÖ Training embeddings directory verified:"
        echo "   Directory: $STANDARD_TRAINING_EMBEDDINGS_DIR"
        echo "   Found: $PKL_COUNT .pkl files"
        echo "   üìä Will use training statistics for normalization"
        TRAINING_EMBEDDINGS_STATUS="‚úÖ AVAILABLE (exact statistics)"
    fi
fi

# Verify evaluation script
if [ ! -f "eval_blip3o_coco.py" ]; then
    echo "‚ùå Updated evaluation script not found: eval_blip3o_coco_updated.py"
    echo "Please ensure the updated evaluation script is in the current directory"
    echo ""
    echo "Expected script features:"
    echo "  ‚Ä¢ Auto-detection of COCO embeddings"
    echo "  ‚Ä¢ Standard temp directory integration"
    echo "  ‚Ä¢ Training statistics loading"
    exit 1
fi

echo "‚úÖ Updated evaluation script found"

echo ""
echo "üöÄ Starting Standard Temp Directory MS-COCO Evaluation..."
echo "========================================"
echo "üéØ Objective: Evaluate model using standard temp directory structure"
echo "üíæ Strategy: Auto-detect embeddings and training statistics"
echo "üî• Benefits:"
echo "   ‚Ä¢ No need to specify embeddings file path"
echo "   ‚Ä¢ Automatic training statistics loading"
echo "   ‚Ä¢ Consistent directory structure"
echo "   ‚Ä¢ Memory-efficient evaluation"
echo "   ‚Ä¢ Reproducible results"
echo ""
echo "Embeddings: Auto-detected from standard temp directory"
echo "Training Statistics: $TRAINING_EMBEDDINGS_STATUS"
echo "Expected Performance: ~0.912 (training reference)"
echo ""

# Build evaluation command - using auto-detection
EVAL_CMD="python eval_blip3o_coco.py \
    --model_path \"$MODEL_PATH\" \
    --output_dir \"$OUTPUT_DIR\" \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --save_results"

# The script will auto-detect:
# - COCO embeddings from $STANDARD_COCO_EMBEDDINGS_DIR/coco_embeddings_consolidated.pkl
# - Training embeddings from $STANDARD_TRAINING_EMBEDDINGS_DIR

# Add optional parameters
if [ "$USE_HEUN" = true ]; then
    EVAL_CMD="$EVAL_CMD --use_heun"
fi

if [ -n "$MAX_SAMPLES" ] && [ "$MAX_SAMPLES" != "None" ]; then
    EVAL_CMD="$EVAL_CMD --max_samples $MAX_SAMPLES"
fi

echo "Executing: $EVAL_CMD"
echo ""
echo "üîç Auto-detection will look for:"
echo "   COCO embeddings: $COCO_CONSOLIDATED_FILE"
echo "   Training embeddings: $STANDARD_TRAINING_EMBEDDINGS_DIR"
echo ""

# Monitor initial GPU memory
echo "üìä Initial GPU Memory Status:"
nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits | \
    awk '{printf "GPU: %s | Total: %s MB | Used: %s MB | Free: %s MB\n", $1, $2, $3, $4}'

echo ""

# Run evaluation
eval $EVAL_CMD

EVAL_EXIT_CODE=$?

echo ""
echo "=================================================================="
echo "üìä Standard Temp Directory MS-COCO Evaluation Results"
echo "=================================================================="

if [ $EVAL_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Standard temp directory MS-COCO evaluation completed successfully!"
    
    # Find and display results
    RESULTS_FILE="$OUTPUT_DIR/coco_evaluation_precomputed.json"
    
    if [ -f "$RESULTS_FILE" ]; then
        echo ""
        echo "üìã Results Summary (Standard Temp Directory Evaluation):"
        echo "=============================================="
        
        # Extract key metrics using Python
        python -c "
import json
import sys
try:
    with open('$RESULTS_FILE', 'r') as f:
        metrics = json.load(f)
    
    # Main results
    current_sim = metrics.get('eval_clip_similarity', 0)
    training_ref = 0.912  # From training logs
    diff_pct = ((current_sim - training_ref) / training_ref) * 100 if training_ref > 0 else 0
    
    print(f'üéØ Current CLIP Similarity: {current_sim:.4f}')
    print(f'üìö Training Reference: {training_ref:.4f}')
    print(f'üìä Difference: {diff_pct:+.1f}%')
    
    # Status assessment
    if abs(diff_pct) < 5:
        print(f'‚úÖ STATUS: Very close to training performance!')
    elif abs(diff_pct) < 15:
        print(f'üìä STATUS: Reasonably close to training performance')
    else:
        print(f'‚ö†Ô∏è STATUS: Significant difference from training')
    
    print(f'')
    print(f'üìÅ Standard Temp Directory Status:')
    std_temp = metrics.get('standard_temp_directory', False)
    memory_efficient = metrics.get('memory_efficient', False)
    print(f'   Standard Temp Directory: {\"‚úÖ ENABLED\" if std_temp else \"‚ùå DISABLED\"}')
    print(f'   Memory-Efficient Mode: {\"‚úÖ ENABLED\" if memory_efficient else \"‚ùå DISABLED\"}')
    
    if std_temp:
        print(f'   üìÇ Embeddings Source: Standard temp directory')
        print(f'   üîó Consistent with training structure')
        print(f'   üöÄ Benefits: Auto-detection, consistent paths')
    
    print(f'')
    print(f'üèÜ Quality Distribution:')
    print(f'   High Quality (>0.7): {metrics.get(\"eval_high_quality\", 0)*100:.1f}%')
    print(f'   Very High Quality (>0.8): {metrics.get(\"eval_very_high_quality\", 0)*100:.1f}%')
    print(f'   Excellent Quality (>0.9): {metrics.get(\"eval_excellent_quality\", 0)*100:.1f}%')
    
    print(f'')
    print(f'üìä Evaluation Details:')
    print(f'   Samples Evaluated: {metrics.get(\"eval_samples\", 0):,}')
    print(f'   Success Rate: {metrics.get(\"eval_success_rate\", 0)*100:.1f}%')
    print(f'   Evaluation Time: {metrics.get(\"evaluation_time_seconds\", 0):.1f} seconds')
    print(f'   Inference Steps: {metrics.get(\"inference_steps\", 0)}')
    print(f'   Solver: {\"Heun\" if metrics.get(\"use_heun_solver\", False) else \"Euler\"}')
    
    # Normalization status
    training_stats = metrics.get('training_statistics_applied', False)
    denorm_applied = metrics.get('denormalization_applied', False)
    print(f'')
    print(f'üîß Normalization Status:')
    print(f'   Training Statistics: {\"‚úÖ APPLIED\" if training_stats else \"‚ùå NOT APPLIED\"}')
    print(f'   Denormalization: {\"‚úÖ APPLIED\" if denorm_applied else \"‚ùå NOT APPLIED\"}')
    
    # Directory structure summary
    print(f'')
    if std_temp and memory_efficient:
        print(f'üéâ STANDARD TEMP DIRECTORY SUCCESS!')
        print(f'   ‚úÖ Auto-detected COCO embeddings')
        print(f'   ‚úÖ Used standard temp directory structure')
        print(f'   ‚úÖ Consistent with training embeddings location')
        print(f'   ‚úÖ Memory-efficient evaluation')
        
        if abs(diff_pct) < 10:
            print(f'   üéØ Performance maintained with standard structure!')
        
    # Performance assessment
    print(f'')
    if training_stats and denorm_applied and std_temp:
        if abs(diff_pct) < 5:
            print(f'üéâ ASSESSMENT: EXCELLENT - Standard structure with optimal performance!')
            print(f'   The model performs very similarly to training using the standard temp directory.')
        elif abs(diff_pct) < 15:
            print(f'‚úÖ ASSESSMENT: GOOD - Standard structure with close performance')
            print(f'   Small differences while achieving directory consistency.')
        else:
            print(f'‚ö†Ô∏è ASSESSMENT: INVESTIGATION NEEDED - Check normalization')
            print(f'   Consider verifying training statistics integration.')
    else:
        print(f'‚ö†Ô∏è ASSESSMENT: Incomplete standard structure integration')
        print(f'   Some features may not be fully utilizing the standard temp directory.')
        
except Exception as e:
    print(f'Could not parse results: {e}')
    sys.exit(1)
"
        
        echo ""
        echo "üìÅ Results saved to: $OUTPUT_DIR"
        echo "üìÑ Full results: $RESULTS_FILE"
        
        # Check for plots
        PLOTS_FILE="$OUTPUT_DIR/coco_evaluation_precomputed.png"
        if [ -f "$PLOTS_FILE" ]; then
            echo "üìä Visualizations: $PLOTS_FILE"
        fi
    else
        echo "‚ö†Ô∏è No results file found"
        echo "Checking output directory contents:"
        ls -la "$OUTPUT_DIR" 2>/dev/null || echo "Output directory not found"
    fi
    
    echo ""
    echo "üéØ Standard Temp Directory Benefits:"
    echo "======================================"
    echo "‚úÖ Auto-detected COCO embeddings from standard location"
    echo "‚úÖ Used consistent directory structure with training"
    echo "‚úÖ Automatically loaded training statistics for normalization"
    echo "‚úÖ No need to specify embeddings file paths manually"
    echo "‚úÖ Memory-efficient evaluation"
    echo "‚úÖ Reproducible results across evaluations"
    echo "‚úÖ Simplified job script configuration"
    
    echo ""
    echo "üìÅ Directory Structure Used:"
    echo "   Base: $STANDARD_EMBEDDINGS_BASE"
    echo "   Training: $STANDARD_TRAINING_EMBEDDINGS_DIR"
    echo "   COCO: $STANDARD_COCO_EMBEDDINGS_DIR"
    
    echo ""
    echo "üí° Next Steps:"
    if [ -f "$RESULTS_FILE" ]; then
        python -c "
import json
try:
    with open('$RESULTS_FILE', 'r') as f:
        metrics = json.load(f)
    similarity = metrics.get('eval_clip_similarity', 0)
    
    if similarity > 0.8:
        print('‚Ä¢ EXCELLENT performance! Consider:')
        print('  - Running full evaluation (remove --max_samples)')
        print('  - Testing on additional datasets')
        print('  - Deploying the model')
    elif similarity > 0.6:
        print('‚Ä¢ GOOD performance! To improve:')
        print('  - Train with more data or longer')
        print('  - Fine-tune hyperparameters')
        print('  - Check model capacity')
    elif similarity > 0.4:
        print('‚Ä¢ FAIR performance! Consider:')
        print('  - Reviewing training setup')
        print('  - Checking normalization')
        print('  - Increasing model size')
    else:
        print('‚Ä¢ Performance needs investigation:')
        print('  - Verify model loading')
        print('  - Check normalization statistics')
        print('  - Review training logs')
        
    print('‚Ä¢ Standard temp directory is working correctly!')
    print('‚Ä¢ Future evaluations will auto-detect embeddings')
except:
    print('‚Ä¢ Review detailed results in output directory')
    print('‚Ä¢ Standard temp directory structure is established')
"
    fi
    
    echo ""
    echo "‚úÖ SUCCESS: Standard temp directory MS-COCO evaluation completed!"
    
else
    echo "‚ùå FAILED: Evaluation exit code $EVAL_EXIT_CODE"
    echo ""
    echo "üí° Troubleshooting (Standard Temp Directory):"
    echo "========================================"
    echo "‚Ä¢ Check log files in ./slurm_out/ for detailed error messages"
    echo "‚Ä¢ Verify standard temp directory structure:"
    echo "  - Base: $STANDARD_EMBEDDINGS_BASE"
    echo "  - COCO: $STANDARD_COCO_EMBEDDINGS_DIR"
    echo "  - Training: $STANDARD_TRAINING_EMBEDDINGS_DIR"
    echo "‚Ä¢ Check COCO embeddings file: $COCO_CONSOLIDATED_FILE"
    echo "‚Ä¢ Verify model path and checkpoint format"
    echo "‚Ä¢ Monitor GPU memory usage"
    echo ""
    echo "üîß Quick fixes:"
    echo "‚Ä¢ Reduce batch size: sbatch this_script.job <model_path> <max_samples> 2"
    echo "‚Ä¢ Reduce samples: sbatch this_script.job <model_path> 100"
    echo "‚Ä¢ Check embeddings file:"
    echo "  python -c \"import pickle; print(pickle.load(open('$COCO_CONSOLIDATED_FILE', 'rb')).keys())\""
    echo ""
    echo "üî• Standard Temp Directory Specific Issues:"
    echo "‚Ä¢ If auto-detection fails, check directory permissions"
    echo "‚Ä¢ If COCO embeddings missing, re-extract:"
    echo "  sbatch job_scripts/extract_coco_updated.job"
    echo "‚Ä¢ If training embeddings missing, check training output"
    echo ""
    echo "üìÅ Directory Structure Check:"
    echo "  ls -la $STANDARD_EMBEDDINGS_BASE"
    echo "  ls -la $STANDARD_COCO_EMBEDDINGS_DIR"
    echo "  ls -la $STANDARD_TRAINING_EMBEDDINGS_DIR"
fi

# Final GPU memory status
echo ""
echo "üìä Final GPU Memory Status:"
nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits | \
    awk '{printf "GPU: %s | Total: %s MB | Used: %s MB | Free: %s MB\n", $1, $2, $3, $4}'

echo ""
echo "üèÅ Job completed at $(date)"
echo "=================================================================="

# Show final directory status
echo ""
echo "üìö STANDARD TEMP DIRECTORY EVALUATION SUMMARY:"
echo "This evaluation uses the standard temp directory structure for consistency."
echo ""
echo "üî• STANDARD DIRECTORY BENEFITS:"
echo "  ‚Ä¢ Auto-detection of COCO embeddings"
echo "  ‚Ä¢ Consistent location with training embeddings"
echo "  ‚Ä¢ Automatic training statistics loading"
echo "  ‚Ä¢ No manual path specification needed"
echo "  ‚Ä¢ Reproducible evaluation setup"
echo "  ‚Ä¢ Simplified job script usage"
echo ""
echo "üìÅ Directory Structure:"
echo "  $STANDARD_EMBEDDINGS_BASE/"
echo "  ‚îú‚îÄ‚îÄ patch_only_256_tokens/           (training embeddings)"
echo "  ‚îî‚îÄ‚îÄ coco_embeddings/                 (COCO embeddings)"
echo "      ‚îú‚îÄ‚îÄ coco_embeddings_consolidated.pkl"
echo "      ‚îî‚îÄ‚îÄ coco_embeddings_manifest.json"
echo ""
echo "üéØ Future evaluations will automatically use this structure."
echo "=================================================================="

exit $EVAL_EXIT_CODE