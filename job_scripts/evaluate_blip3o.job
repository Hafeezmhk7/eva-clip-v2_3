#!/bin/bash
#SBATCH --job-name=blip3o_coco_eval_training_stats
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --time=4:00:00
#SBATCH --mem=64G
#SBATCH --output=./slurm_out/blip3o_coco_eval_training_stats_%j.out
#SBATCH --error=./slurm_out/blip3o_coco_eval_training_stats_%j.err

# =============================================================================
# BLIP3-o MS-COCO Evaluation with Training Statistics Integration
# Evaluates trained model using EXACT training normalization statistics
# =============================================================================

echo "üî¨ BLIP3-o MS-COCO Evaluation with Training Statistics Integration"
echo "=================================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "=================================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Configuration based on training setup
MODEL_PATH="/home/azadaianchuk1/eva-clip-v6_2/checkpoints/blip3o_clean_20250803_015324"
COCO_ROOT="./data/coco"
OUTPUT_DIR="./coco_eval_training_stats_$(date +%Y%m%d_%H%M%S)"

# üî• CRITICAL: Training embeddings directory (from training logs)
TRAINING_EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"

# Evaluation parameters (matching training setup)
MAX_SAMPLES=1000  # Evaluate on subset for faster testing
BATCH_SIZE=8
NUM_INFERENCE_STEPS=50
USE_HEUN=true

# Model path - can be provided as argument or use default
if [ -n "$1" ]; then
    MODEL_PATH="$1"
    echo "üìÇ Using provided model path: $MODEL_PATH"
else
    echo "üìÇ Using default model path: $MODEL_PATH"
    # Auto-detect most recent model if default doesn't exist
    if [ ! -d "$MODEL_PATH" ]; then
        echo "üîç Auto-detecting most recent model..."
        MODEL_PATH=$(find ./checkpoints -name "*blip3o*" -type d | sort | tail -1)
        if [ -z "$MODEL_PATH" ]; then
            echo "‚ùå No model found! Please provide model path as argument."
            echo "Usage: sbatch job_scripts/evaluate_blip3o_coco_training_stats.job <model_path>"
            exit 1
        fi
        echo "üìÇ Found model: $MODEL_PATH"
    fi
fi

# COCO root can be provided as second argument
if [ -n "$2" ]; then
    COCO_ROOT="$2"
    echo "üìÇ Using provided COCO root: $COCO_ROOT"
fi

# Training embeddings dir can be provided as third argument
if [ -n "$3" ]; then
    TRAINING_EMBEDDINGS_DIR="$3"
    echo "üìÇ Using provided training embeddings dir: $TRAINING_EMBEDDINGS_DIR"
fi

# Create output directory
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "‚öôÔ∏è MS-COCO Evaluation Configuration (Training Statistics Integration):"
echo "======================================================================="
echo "Model: $MODEL_PATH"
echo "COCO Root: $COCO_ROOT"
echo "Training Embeddings: $TRAINING_EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo "Max Samples: $MAX_SAMPLES"
echo "Batch Size: $BATCH_SIZE"
echo "Inference Steps: $NUM_INFERENCE_STEPS"
echo "Use Heun Solver: $USE_HEUN"
echo ""
echo "üî• Training Statistics Integration:"
echo "   Source: patch_only_256_tokens embeddings"
echo "   Method: Ultra-conservative percentile-based"
echo "   Scale factor: 1.5"
echo "   Expected similarity: ~0.912 (training reference)"
echo ""

# Verify model exists
if [ ! -d "$MODEL_PATH" ]; then
    echo "‚ùå Model directory not found: $MODEL_PATH"
    echo "Available models:"
    ls -la ./checkpoints/ 2>/dev/null || echo "No checkpoints found"
    exit 1
fi

# Check for required model files
MODEL_CONFIG="$MODEL_PATH/config.json"
MODEL_WEIGHTS_SAFETENSORS="$MODEL_PATH/model.safetensors"
MODEL_WEIGHTS_BIN="$MODEL_PATH/pytorch_model.bin"
CHECKPOINT_FILES="$MODEL_PATH/checkpoint_step_*.pt"

# Check what format the model is in
if [ -f "$MODEL_CONFIG" ] && ([ -f "$MODEL_WEIGHTS_SAFETENSORS" ] || [ -f "$MODEL_WEIGHTS_BIN" ]); then
    echo "‚úÖ HuggingFace format model detected"
elif ls $CHECKPOINT_FILES 1> /dev/null 2>&1; then
    echo "‚úÖ Checkpoint format model detected"
    LATEST_CHECKPOINT=$(ls -t $CHECKPOINT_FILES | head -1)
    echo "   Latest checkpoint: $LATEST_CHECKPOINT"
else
    echo "‚ùå No valid model files found in: $MODEL_PATH"
    echo "Expected:"
    echo "  - HuggingFace format: config.json + (model.safetensors OR pytorch_model.bin)"
    echo "  - Checkpoint format: checkpoint_step_*.pt"
    echo "Model directory contents:"
    ls -la "$MODEL_PATH"
    exit 1
fi

echo "‚úÖ Model verified: $MODEL_PATH"

# üî• CRITICAL: Verify training embeddings directory exists
echo ""
echo "üîç Verifying training embeddings directory..."
if [ ! -d "$TRAINING_EMBEDDINGS_DIR" ]; then
    echo "‚ùå Training embeddings directory not found: $TRAINING_EMBEDDINGS_DIR"
    echo ""
    echo "‚ö†Ô∏è IMPORTANT: Training embeddings are needed for accurate normalization!"
    echo ""
    echo "Expected structure:"
    echo "  $TRAINING_EMBEDDINGS_DIR/"
    echo "  ‚îú‚îÄ‚îÄ embeddings_shard_00000_patch_only.pkl"
    echo "  ‚îú‚îÄ‚îÄ embeddings_shard_00001_patch_only.pkl"
    echo "  ‚îî‚îÄ‚îÄ ..."
    echo ""
    echo "Options:"
    echo "  1. Provide correct path as 3rd argument"
    echo "  2. Evaluation will use approximate fallback normalization"
    echo ""
    echo "‚ö†Ô∏è Proceeding with fallback - results may not be fully accurate"
    TRAINING_EMBEDDINGS_STATUS="‚ùå NOT FOUND (using fallback)"
else
    # Check for .pkl files
    PKL_COUNT=$(find "$TRAINING_EMBEDDINGS_DIR" -name "*.pkl" | wc -l)
    if [ $PKL_COUNT -eq 0 ]; then
        echo "‚ùå No .pkl files found in training embeddings directory"
        echo "Directory contents:"
        ls -la "$TRAINING_EMBEDDINGS_DIR"
        TRAINING_EMBEDDINGS_STATUS="‚ùå NO FILES (using fallback)"
    else
        echo "‚úÖ Training embeddings directory verified:"
        echo "   Directory: $TRAINING_EMBEDDINGS_DIR"
        echo "   Found: $PKL_COUNT .pkl files"
        echo "   üìä Will recompute EXACT training statistics"
        TRAINING_EMBEDDINGS_STATUS="‚úÖ AVAILABLE (exact statistics)"
    fi
fi

# Check if COCO dataset exists
echo ""
echo "üîç Verifying COCO dataset..."
if [ ! -d "$COCO_ROOT" ]; then
    echo "‚ùå COCO dataset not found: $COCO_ROOT"
    echo ""
    echo "üí° To download COCO dataset:"
    echo "   python src/data_hand/download_coco.py --coco_root $COCO_ROOT"
    echo ""
    echo "Or download manually:"
    echo "   mkdir -p $COCO_ROOT"
    echo "   # Download val2017.zip and annotations_trainval2017.zip"
    echo "   # Extract to create $COCO_ROOT/images/val2017/ and $COCO_ROOT/annotations/"
    exit 1
fi

# Verify COCO structure
COCO_IMAGES="$COCO_ROOT/val2017/"
COCO_ANNOTATIONS="$COCO_ROOT/annotations/captions_val2017.json"

if [ ! -d "$COCO_IMAGES" ]; then
    echo "‚ùå COCO images directory not found: $COCO_IMAGES"
    exit 1
fi

if [ ! -f "$COCO_ANNOTATIONS" ]; then
    echo "‚ùå COCO annotations file not found: $COCO_ANNOTATIONS"
    exit 1
fi

# Count available images
IMAGE_COUNT=$(find "$COCO_IMAGES" -name "*.jpg" | wc -l)
echo "‚úÖ COCO dataset verified:"
echo "   Images directory: $COCO_IMAGES"
echo "   Annotations file: $COCO_ANNOTATIONS"
echo "   Available images: $IMAGE_COUNT"

if [ $IMAGE_COUNT -eq 0 ]; then
    echo "‚ùå No images found in COCO images directory"
    exit 1
fi

# Verify evaluation script
if [ ! -f "eval_blip3o_coco.py" ]; then
    echo "‚ùå Evaluation script not found: eval_blip3o_coco.py"
    echo "Please ensure the MS-COCO evaluation script is in the current directory"
    exit 1
fi

echo "‚úÖ Evaluation script found"

echo ""
echo "üöÄ Starting MS-COCO Evaluation with Training Statistics Integration..."
echo "====================================================================="
echo "üéØ Objective: Evaluate model using EXACT training normalization"
echo "üìä Method: Reproduce training evaluation conditions exactly"
echo "üî• Key Features:"
echo "   ‚Ä¢ Same CLIP normalizer statistics as training"
echo "   ‚Ä¢ Same denormalization process"
echo "   ‚Ä¢ Same generation method (Heun's solver)"
echo "   ‚Ä¢ Same metrics computation"
echo "   ‚Ä¢ Training reference comparison"
echo ""
echo "Dataset: MS-COCO val2017 ($IMAGE_COUNT images available)"
echo "Training Embeddings: $TRAINING_EMBEDDINGS_STATUS"
echo "Expected Training Similarity: ~0.912 (91.2%)"
echo ""

# Build evaluation command with training statistics integration
if [ "$USE_HEUN" = true ]; then
    HEUN_FLAG="--use_heun"
else
    HEUN_FLAG=""
fi

EVAL_CMD="python eval_blip3o_coco.py \
    --model_path \"$MODEL_PATH\" \
    --coco_root \"$COCO_ROOT\" \
    --training_embeddings_dir \"$TRAINING_EMBEDDINGS_DIR\" \
    --output_dir \"$OUTPUT_DIR\" \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --save_results \
    $HEUN_FLAG"

# Add max_samples if specified
if [ "$MAX_SAMPLES" != "null" ] && [ -n "$MAX_SAMPLES" ]; then
    EVAL_CMD="$EVAL_CMD --max_samples $MAX_SAMPLES"
fi

echo "Executing: $EVAL_CMD"
echo ""

# Run evaluation
eval $EVAL_CMD

EVAL_EXIT_CODE=$?

echo ""
echo "=================================================================="
echo "üìä MS-COCO Evaluation Results (Training Statistics Integration)"
echo "=================================================================="

if [ $EVAL_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ MS-COCO evaluation completed successfully!"
    
    # Find and display results
    RESULTS_FILE="$OUTPUT_DIR/coco_evaluation_training_integrated.json"
    METRICS_FILE="$OUTPUT_DIR/coco_metrics_training_integrated.json"
    PLOTS_FILE="$OUTPUT_DIR/coco_evaluation_training_integrated.png"
    
    if [ -f "$METRICS_FILE" ]; then
        echo ""
        echo "üìã Results Summary (Training Statistics Integration):"
        echo "==================================================="
        
        # Extract key metrics using Python with training comparison
        python -c "
import json
import sys
try:
    with open('$METRICS_FILE', 'r') as f:
        metrics = json.load(f)
    
    # Main results
    current_sim = metrics.get('eval_clip_similarity', 0)
    training_ref = 0.912  # From training logs
    diff_pct = ((current_sim - training_ref) / training_ref) * 100 if training_ref > 0 else 0
    
    print(f'üéØ Current CLIP Similarity: {current_sim:.4f}')
    print(f'üìö Training Reference: {training_ref:.4f}')
    print(f'üìä Difference: {diff_pct:+.1f}%')
    
    # Status assessment
    if abs(diff_pct) < 5:
        print(f'‚úÖ STATUS: Very close to training performance!')
    elif abs(diff_pct) < 15:
        print(f'üìä STATUS: Reasonably close to training performance')
    else:
        print(f'‚ö†Ô∏è STATUS: Significant difference from training')
    
    print(f'')
    print(f'üî• Training Integration Status:')
    training_stats = metrics.get('training_statistics_applied', False)
    denorm_applied = metrics.get('denormalization_applied', False)
    print(f'   Training Statistics: {\"‚úÖ APPLIED\" if training_stats else \"‚ùå NOT APPLIED\"}')
    print(f'   Denormalization: {\"‚úÖ APPLIED\" if denorm_applied else \"‚ùå NOT APPLIED\"}')
    print(f'   Primary Metrics: {metrics.get(\"primary_metrics_source\", \"unknown\")} space')
    
    if 'denorm_clip_similarity' in metrics and 'norm_clip_similarity' in metrics:
        denorm_sim = metrics['denorm_clip_similarity']
        norm_sim = metrics['norm_clip_similarity']
        print(f'')
        print(f'üîÑ Normalized vs Denormalized:')
        print(f'   Normalized (model space): {norm_sim:.4f}')
        print(f'   Denormalized (training space): {denorm_sim:.4f}')
        print(f'   üìä Training-comparable: {denorm_sim:.4f}')
    
    print(f'')
    print(f'üèÜ Quality Distribution:')
    print(f'   High Quality (>0.7): {metrics.get(\"eval_high_quality\", 0)*100:.1f}%')
    print(f'   Very High Quality (>0.8): {metrics.get(\"eval_very_high_quality\", 0)*100:.1f}%')
    print(f'   Excellent Quality (>0.9): {metrics.get(\"eval_excellent_quality\", 0)*100:.1f}%')
    
    print(f'')
    print(f'üìä Evaluation Details:')
    print(f'   Samples Evaluated: {metrics.get(\"eval_samples\", 0):,}')
    print(f'   Success Rate: {metrics.get(\"eval_success_rate\", 0)*100:.1f}%')
    print(f'   Evaluation Time: {metrics.get(\"evaluation_time_seconds\", 0):.1f} seconds')
    print(f'   Inference Steps: {metrics.get(\"inference_steps\", 0)}')
    print(f'   Solver: {\"Heun\" if metrics.get(\"use_heun_solver\", False) else \"Euler\"}')
    
    # Training embeddings source info
    training_source = metrics.get('training_embeddings_source', 'unknown')
    print(f'')
    print(f'üìÇ Training Statistics Source:')
    print(f'   Directory: {training_source}')
    
    # Performance assessment based on training comparison
    print(f'')
    if training_stats and denorm_applied:
        if abs(diff_pct) < 5:
            print(f'üéâ ASSESSMENT: EXCELLENT - Evaluation successfully replicates training!')
            print(f'   The model performs very similarly to training conditions.')
        elif abs(diff_pct) < 15:
            print(f'‚úÖ ASSESSMENT: GOOD - Close to training performance')
            print(f'   Small differences likely due to dataset or evaluation differences.')
        else:
            print(f'‚ö†Ô∏è ASSESSMENT: INVESTIGATION NEEDED - Significant difference')
            print(f'   Check model compatibility or normalization issues.')
    else:
        print(f'‚ö†Ô∏è ASSESSMENT: Incomplete training integration')
        print(f'   Results may not be fully comparable to training performance.')
        
except Exception as e:
    print(f'Could not parse results: {e}')
    sys.exit(1)
"
        
        echo ""
        echo "üìÅ Results saved to: $OUTPUT_DIR"
        if [ -f "$RESULTS_FILE" ]; then
            echo "üìÑ Full results: $RESULTS_FILE"
        fi
        if [ -f "$PLOTS_FILE" ]; then
            echo "üìä Visualizations: $PLOTS_FILE"
        fi
    else
        echo "‚ö†Ô∏è No metrics file found"
        echo "Checking output directory contents:"
        ls -la "$OUTPUT_DIR" 2>/dev/null || echo "Output directory not found"
    fi
    
    echo ""
    echo "üéØ Training Statistics Integration Guide:"
    echo "========================================"
    echo "‚Ä¢ Training Reference: 0.912 (91.2% CLIP similarity from training)"
    echo "‚Ä¢ Expected Range: 0.85-0.95 (close to training)"
    echo "‚Ä¢ Normalization: Ultra-conservative (scale 1.5, percentile-based)"
    echo "‚Ä¢ Denormalization: Required for training-comparable metrics"
    echo ""
    echo "üìä Quality Interpretation:"
    echo "‚Ä¢ >0.9: Excellent reproduction (matching training quality)"
    echo "‚Ä¢ 0.8-0.9: Very good reproduction"
    echo "‚Ä¢ 0.7-0.8: Good reproduction"
    echo "‚Ä¢ <0.7: May indicate issues with model or normalization"
    
    echo ""
    echo "‚úÖ SUCCESS: MS-COCO evaluation with training statistics integration completed!"
    
else
    echo "‚ùå FAILED: Evaluation exit code $EVAL_EXIT_CODE"
    echo ""
    echo "üí° Troubleshooting (Training Statistics Integration):"
    echo "=================================================="
    echo "‚Ä¢ Check log files in ./slurm_out/ for detailed error messages"
    echo "‚Ä¢ Verify model path and checkpoint format compatibility"
    echo "‚Ä¢ Ensure training embeddings directory is accessible:"
    echo "  - Path: $TRAINING_EMBEDDINGS_DIR"
    echo "  - Should contain: *.pkl files from training"
    echo "‚Ä¢ Check COCO dataset structure"
    echo "‚Ä¢ Verify GPU memory - try smaller batch size if OOM"
    echo ""
    echo "üîß Quick fixes:"
    echo "‚Ä¢ Reduce batch size: --batch_size 4"
    echo "‚Ä¢ Reduce samples: --max_samples 100"
    echo "‚Ä¢ Check training embeddings path:"
    echo "  sbatch this_script.job <model_path> <coco_root> <training_embeddings_dir>"
    echo ""
    echo "üî• Training Statistics Issues:"
    echo "‚Ä¢ If training embeddings not found, evaluation will use fallback normalization"
    echo "‚Ä¢ Results may not be fully comparable to training without exact statistics"
    echo "‚Ä¢ Ensure the training embeddings directory from training is accessible"
fi

echo ""
echo "üèÅ Job completed at $(date)"
echo "=================================================================="

# Show final resource usage
echo ""
echo "üìä GPU Resource Usage Summary:"
nvidia-smi --query-gpu=name,memory.total,memory.used,utilization.gpu --format=csv,noheader,nounits | \
    awk 'BEGIN{print "GPU | Total Memory | Used Memory | Utilization"} {printf "%s | %s MB | %s MB | %s%%\n", $1, $2, $3, $4}'

echo ""
echo "üìö EVALUATION SUMMARY (Training Statistics Integration):"
echo "This evaluation integrates with the EXACT training normalization statistics."
echo "It reproduces the training evaluation conditions to provide comparable results."
echo "Key features:"
echo "  ‚Ä¢ Training CLIP normalizer statistics (percentile-based, scale 1.5)"
echo "  ‚Ä¢ Same denormalization process as training"
echo "  ‚Ä¢ Training reference comparison (0.912 similarity)"
echo "  ‚Ä¢ Enhanced error handling and fallback mechanisms"
echo "Results should be directly comparable to training performance metrics."
echo "=================================================================="

exit $EVAL_EXIT_CODE