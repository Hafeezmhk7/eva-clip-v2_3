#!/bin/bash
#SBATCH --job-name=coco_embeddings_extract
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=4:00:00
#SBATCH --mem=64G
#SBATCH --output=./slurm_out/coco_embeddings_extract_%j.out
#SBATCH --error=./slurm_out/coco_embeddings_extract_%j.err

# =============================================================================
# MS-COCO Embedding Extraction for BLIP3-o Evaluation
# Extracts CLIP and EVA-CLIP embeddings from MS-COCO validation dataset
# to enable memory-efficient evaluation
# =============================================================================

echo "üöÄ MS-COCO Embedding Extraction for BLIP3-o Evaluation"
echo "=================================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "=================================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Configuration
COCO_ROOT="./data/coco"
BATCH_SIZE=8
MAX_SAMPLES=1000  # Set to None or remove for all samples
INCLUDE_CLS=true
SAVE_EVERY_N_BATCHES=25

# COCO root can be provided as first argument
if [ -n "$1" ]; then
    COCO_ROOT="$1"
    echo "üìÇ Using provided COCO root: $COCO_ROOT"
fi

# Batch size can be provided as second argument
if [ -n "$2" ]; then
    BATCH_SIZE="$2"
    echo "üìä Using provided batch size: $BATCH_SIZE"
fi

# Max samples can be provided as third argument
if [ -n "$3" ]; then
    MAX_SAMPLES="$3"
    echo "üìà Using provided max samples: $MAX_SAMPLES"
fi

# Create output directory
mkdir -p ./slurm_out

echo ""
echo "‚öôÔ∏è MS-COCO Embedding Extraction Configuration:"
echo "========================================"
echo "COCO Root: $COCO_ROOT"
echo "Batch Size: $BATCH_SIZE"
echo "Max Samples: ${MAX_SAMPLES:-All}"
echo "Include CLS: $INCLUDE_CLS"
echo "Save Every N Batches: $SAVE_EVERY_N_BATCHES"
echo ""
echo "üéØ Purpose: Extract embeddings to avoid GPU memory issues during evaluation"
echo "üìä Output: Consolidated pickle file with CLIP and EVA embeddings"
echo "üíæ Memory Strategy: Save intermediate files every $SAVE_EVERY_N_BATCHES batches"
echo ""

# Verify COCO dataset exists
if [ ! -d "$COCO_ROOT" ]; then
    echo "‚ùå COCO dataset not found: $COCO_ROOT"
    echo ""
    echo "üí° To download COCO dataset:"
    echo "   mkdir -p $COCO_ROOT"
    echo "   cd $COCO_ROOT"
    echo "   # Download validation images"
    echo "   wget http://images.cocodataset.org/zips/val2017.zip"
    echo "   unzip val2017.zip"
    echo "   # Download annotations"
    echo "   wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
    echo "   unzip annotations_trainval2017.zip"
    echo ""
    exit 1
fi

# Verify COCO structure
COCO_IMAGES="$COCO_ROOT/val2017/"
COCO_ANNOTATIONS="$COCO_ROOT/annotations/captions_val2017.json"

if [ ! -d "$COCO_IMAGES" ]; then
    # Try alternative structure
    COCO_IMAGES="$COCO_ROOT/images/val2017/"
    if [ ! -d "$COCO_IMAGES" ]; then
        echo "‚ùå COCO images directory not found: $COCO_IMAGES"
        echo "Expected structure:"
        echo "  $COCO_ROOT/val2017/ (or $COCO_ROOT/images/val2017/)"
        exit 1
    fi
fi

if [ ! -f "$COCO_ANNOTATIONS" ]; then
    echo "‚ùå COCO annotations file not found: $COCO_ANNOTATIONS"
    exit 1
fi

# Count available images
IMAGE_COUNT=$(find "$COCO_IMAGES" -name "*.jpg" | wc -l)
echo "‚úÖ COCO dataset verified:"
echo "   Images directory: $COCO_IMAGES"
echo "   Annotations file: $COCO_ANNOTATIONS"
echo "   Available images: $IMAGE_COUNT"

if [ $IMAGE_COUNT -eq 0 ]; then
    echo "‚ùå No images found in COCO images directory"
    exit 1
fi

# Verify extraction script
if [ ! -f "extract_coco_embeddings.py" ]; then
    echo "‚ùå Extraction script not found: extract_coco_embeddings.py"
    echo "Please ensure the script is in the current directory"
    exit 1
fi

echo "‚úÖ Extraction script found"

echo ""
echo "üöÄ Starting MS-COCO Embedding Extraction..."
echo "========================================="
echo "üéØ Objective: Extract CLIP and EVA embeddings for memory-efficient evaluation"
echo "üìä Strategy: Process in batches and save intermediate files"
echo "üíæ Memory: Automatic cleanup between batches"
echo "üîÑ Recovery: Can resume from intermediate files if interrupted"
echo ""
echo "Dataset: MS-COCO val2017 ($IMAGE_COUNT images available)"
echo "Expected output: Consolidated embeddings file"
echo ""

# Build extraction command
EXTRACT_CMD="python extract_coco_embeddings.py \
    --coco_root \"$COCO_ROOT\" \
    --batch_size $BATCH_SIZE \
    --save_every_n_batches $SAVE_EVERY_N_BATCHES"

# Add optional parameters
if [ "$INCLUDE_CLS" = true ]; then
    EXTRACT_CMD="$EXTRACT_CMD --include_cls"
fi

if [ -n "$MAX_SAMPLES" ] && [ "$MAX_SAMPLES" != "None" ]; then
    EXTRACT_CMD="$EXTRACT_CMD --max_samples $MAX_SAMPLES"
fi

echo "Executing: $EXTRACT_CMD"
echo ""

# Run extraction
eval $EXTRACT_CMD

EXTRACT_EXIT_CODE=$?

echo ""
echo "=================================================================="
echo "üìä MS-COCO Embedding Extraction Results"
echo "=================================================================="

if [ $EXTRACT_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ MS-COCO embedding extraction completed successfully!"
    
    # Look for output files
    echo ""
    echo "üìã Generated Files:"
    echo "=================="
    
    # Check for consolidated file
    if [ -f "./coco_embeddings/coco_embeddings_consolidated.pkl" ]; then
        CONSOLIDATED_FILE="./coco_embeddings/coco_embeddings_consolidated.pkl"
    elif [ -f "coco_embeddings_consolidated.pkl" ]; then
        CONSOLIDATED_FILE="coco_embeddings_consolidated.pkl"
    else
        CONSOLIDATED_FILE=$(find . -name "coco_embeddings_consolidated.pkl" 2>/dev/null | head -1)
    fi
    
    if [ -n "$CONSOLIDATED_FILE" ] && [ -f "$CONSOLIDATED_FILE" ]; then
        FILE_SIZE=$(stat --format="%s" "$CONSOLIDATED_FILE" 2>/dev/null || echo "0")
        FILE_SIZE_GB=$(echo "scale=2; $FILE_SIZE / 1024 / 1024 / 1024" | bc -l 2>/dev/null || echo "?.??")
        
        echo "‚úÖ Consolidated embeddings file: $CONSOLIDATED_FILE"
        echo "   File size: ${FILE_SIZE_GB} GB"
        
        # Check manifest
        MANIFEST_FILE="${CONSOLIDATED_FILE%.*}_manifest.json"
        if [ -f "$MANIFEST_FILE" ]; then
            echo "‚úÖ Manifest file: $MANIFEST_FILE"
            
            # Extract summary from manifest
            python -c "
import json
import sys
try:
    with open('$MANIFEST_FILE', 'r') as f:
        manifest = json.load(f)
    
    print(f'üìä Extraction Summary:')
    print(f'   Total samples: {manifest.get(\"total_samples\", \"unknown\"):,}')
    print(f'   CLIP shape: {manifest.get(\"clip_shape\", \"unknown\")}')
    print(f'   EVA shape: {manifest.get(\"eva_shape\", \"unknown\")}')
    print(f'   Include CLS: {manifest.get(\"include_cls\", \"unknown\")}')
    print(f'   Tokens per sample: {manifest.get(\"tokens\", \"unknown\")}')
    print(f'   Created: {manifest.get(\"created\", \"unknown\")}')
    
except Exception as e:
    print(f'Could not parse manifest: {e}')
    sys.exit(1)
"
        fi
        
        echo ""
        echo "üéâ SUCCESS: Embeddings extracted and ready for evaluation!"
        echo ""
        echo "üí° Usage in evaluation:"
        echo "sbatch job_scripts/evaluate_blip3o_with_precomputed.job <model_path> $CONSOLIDATED_FILE"
        echo ""
        echo "Or manually:"
        echo "python eval_blip3o_coco.py \\"
        echo "  --model_path <model_path> \\"
        echo "  --coco_embeddings_file $CONSOLIDATED_FILE"
        
    else
        echo "‚ö†Ô∏è Consolidated file not found - check for intermediate files"
        echo "Intermediate files:"
        find . -name "coco_embeddings_*.pkl" 2>/dev/null | head -5
    fi
    
    # Show disk usage
    echo ""
    echo "üíæ Disk Usage:"
    if [ -d "./coco_embeddings" ]; then
        du -sh ./coco_embeddings 2>/dev/null || echo "Could not determine disk usage"
    fi
    
else
    echo "‚ùå FAILED: Embedding extraction exit code $EXTRACT_EXIT_CODE"
    echo ""
    echo "üí° Troubleshooting:"
    echo "=================="
    echo "‚Ä¢ Check log files in ./slurm_out/ for detailed error messages"
    echo "‚Ä¢ Verify COCO dataset structure and accessibility"
    echo "‚Ä¢ Monitor GPU memory usage - try smaller batch size if OOM"
    echo "‚Ä¢ Check available disk space for output files"
    echo ""
    echo "üîß Recovery options:"
    echo "‚Ä¢ Reduce batch size: sbatch this_script.job <coco_root> 4"
    echo "‚Ä¢ Limit samples: modify MAX_SAMPLES in script"
    echo "‚Ä¢ Resume from intermediate files: run with --consolidate_only"
    echo ""
    echo "üîç Quick checks:"
    echo "‚Ä¢ GPU memory: nvidia-smi"
    echo "‚Ä¢ Disk space: df -h"
    echo "‚Ä¢ COCO structure: ls -la $COCO_ROOT"
    
    # Show any intermediate files that might exist
    echo ""
    echo "üîç Checking for intermediate files..."
    INTERMEDIATE_FILES=$(find . -name "coco_embeddings_*.pkl" 2>/dev/null | wc -l)
    if [ $INTERMEDIATE_FILES -gt 0 ]; then
        echo "Found $INTERMEDIATE_FILES intermediate files:"
        find . -name "coco_embeddings_*.pkl" 2>/dev/null | head -3
        echo ""
        echo "üí° You can consolidate these files by running:"
        echo "python extract_coco_embeddings.py --consolidate_only"
    else
        echo "No intermediate files found"
    fi
fi

echo ""
echo "üìä Final GPU Memory Usage:"
nvidia-smi --query-gpu=name,memory.total,memory.used,utilization.gpu --format=csv,noheader,nounits | \
    awk 'BEGIN{print "GPU | Total Memory | Used Memory | Utilization"} {printf "%s | %s MB | %s MB | %s%%\n", $1, $2, $3, $4}'

echo ""
echo "üèÅ Job completed at $(date)"
echo "=================================================================="

# Final status summary
echo ""
echo "üìö MS-COCO EMBEDDING EXTRACTION SUMMARY:"
echo "This job extracts CLIP and EVA-CLIP embeddings from MS-COCO validation dataset."
echo "The extracted embeddings can be used for memory-efficient evaluation of BLIP3-o models."
echo ""
echo "Benefits:"
echo "  ‚Ä¢ Avoids GPU memory issues during evaluation"
echo "  ‚Ä¢ Faster evaluation (no need to re-extract embeddings)"
echo "  ‚Ä¢ Consistent embeddings across multiple evaluations"
echo "  ‚Ä¢ Enables evaluation with larger batch sizes"
echo ""
echo "Next step: Use the consolidated embeddings file in your evaluation script."
echo "=================================================================="

exit $EXTRACT_EXIT_CODE